{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"AGEC 652 - Lecture 2.3\"\n",
        "subtitle: \"Numerical integration\"\n",
        "author: \"Diego S. Cardoso\"\n",
        "institute: \"Purdue University\"\n",
        "execute:\n",
        "  echo: true\n",
        "format:\n",
        "  revealjs: \n",
        "    theme: [white, ./../agec_652_style.css]\n",
        "    slide-number: c\n",
        "    show-slide-number: all\n",
        "    code-block-bg: true\n",
        "    code-block-border-left: \"#31BAE9\"\n",
        "    code-copy: hover\n",
        "    fig-width: 8\n",
        "    fig-height: 4\n",
        "    chalkboard:\n",
        "      theme: whiteboard\n",
        "      chalk-effect: 0.1\n",
        "editor:\n",
        "  render-on-save: false\n",
        "---"
      ],
      "id": "e6805045"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "using Pkg\n",
        "Pkg.activate(\".\")\n",
        "Pkg.instantiate()\n",
        "Pkg.add(\"BenchmarkTools\")"
      ],
      "id": "c455b15e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Course Roadmap {background-color=\"gold\"}\n",
        "\n",
        "1.  [Introduction to Scientific Computing]{.gray}\n",
        "2.  [Fundamentals of numerical methods]{.gray}\n",
        "3.  **Systems of equations**\n",
        "    1. Linear systems\n",
        "    2. Nonlinear systems: derivative-free methods\n",
        "    3. Nonlinear systems: Newton and Quasi-Newton methods\n",
        "4.  Optimization\n",
        "5.  Structural estimation\n",
        "\n",
        "## Agenda {background-color=\"gold\"}\n",
        "\n",
        "- Today we will start our journey solving equations\n",
        "- Our first stop is with a familiar problem: systems of equations\n",
        "- Although simple from a math perspective, these problems illustrate some of the challenges with solving equations using the computer\n",
        "\n",
        "\n",
        "## Main references for today {background-color=\"gold\"}\n",
        "\n",
        "-   Miranda & Fackler (2002), Ch. 2\n",
        "-   Judd (1998), Ch. 3\n",
        "-   Lecture notes for Ivan Rudik's *Dynamic Optimization* (Cornell) \n",
        "\n",
        "\n",
        "## Linear equations in Economics\n",
        "\n",
        "(Systems of) Linear equations are very common in Economics\n",
        "\n",
        "$$Ax = b$$\n",
        "where $A$ is a $n \\times n$ matrix, $b$ and $x$ are $n$-vectors\n",
        "\n",
        "Examples?\n",
        "\n",
        ". . .\n",
        "\n",
        "- Comparative statics\n",
        "- General equilibrium models with linear functions\n",
        "- Log-linearized models\n",
        "- Steady-state distributions of discrete stochastic processes\n",
        "\n",
        "\n",
        "\n",
        "## Solving linear equations in Julia\n",
        "\n",
        "Solving linear systems is generally very easy in programming languages\n"
      ],
      "id": "5542b5af"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "A = [-3 2 3; -3 2 1; 3 0 0]; b = [10; 8; -3];\n",
        "x = A\\b # This is an optimized division, faster than inverting A (more on that later)"
      ],
      "id": "033ead24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ". . .\n",
        "\n",
        "- So why bother?\n",
        "\n",
        "\n",
        "\n",
        "## Linear equations: Why bother?\n",
        "\n",
        "1. It's a *building block*: many methods decompose more complicated problems into sequences of linear problems\n",
        "   - Understanding how we solve linear systems is crucial to understanding other methods\n",
        "\n",
        ". . .\n",
        "\n",
        "2. It uses key concepts of numerical analysis, such as iterative methods\n",
        "  - Seeing these ideas in action with a familiar problem will help you understand more complex ones\n",
        "\n",
        ". . .\n",
        "\n",
        "3. Like any other numerical method, it is prone to limited precision issues that grow with repeated operations\n",
        "  - In linear systems we can see these issues in a transparent and intuitive way\n",
        "\n",
        "\n",
        "\n",
        "## Solving linear equations\n",
        "\n",
        "OK, so how does the computer actually solve linear equations?\n",
        "\n",
        "Methods come in two flavors:\n",
        "\n",
        "1. Direct methods\n",
        "  - We solve it in one pass and get a solution with a finite number of operations\n",
        "2. Iterative methods\n",
        "  - We solve the same problem repeatedly until results converge to a solution\n",
        "\n",
        "\n",
        "\n",
        "## Solving linear equations: direct methods\n",
        "\n",
        "\n",
        "Let's start with the simplest case: a *lower triangular* matrix\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "a_{11} & 0      & 0      & \\cdots & 0 \\\\\n",
        "a_{21} & a_{22} & 0      & \\cdots & 0 \\\\\n",
        "a_{31} & a_{32} & a_{33} & \\cdots & 0 \\\\\n",
        "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "a_{n1} & a_{n2} & a_{n3} & \\cdots & a_{nn} \\\\\n",
        "\\end{bmatrix}\n",
        ", x =\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "x_3 \\\\\n",
        "\\vdots \\\\\n",
        "x_n\n",
        "\\end{bmatrix}\n",
        ", b = \n",
        "\\begin{bmatrix}\n",
        "b_1 \\\\\n",
        "b_2 \\\\\n",
        "b_3 \\\\\n",
        "\\vdots \\\\\n",
        "b_n\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "How do we solve this? \n",
        "\n",
        ". . .\n",
        "\n",
        "Easy, forward substitution!\n",
        "\n",
        "\n",
        "\n",
        "## Solving linear equations: forward substitution\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "x_1 = &  b_1/a_{11} \\\\\n",
        "x_2 = & (b_2 - a_{21}x_1)/a_{22} \\\\\n",
        "x_3 = & (b_3 - a_{31}x_1 - a_{32}x_2)/a_{33} \\\\\n",
        "\\vdots \\\\\n",
        "x_n = & (b_n - a_{n1}x_1 - a_{n2}x_2 - \\cdots)/a_{nn} \\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        ". . .\n",
        "\n",
        "We can write a simple algorithm to solve it: $x_i=\\left(b_i-\\sum^{i-1}_{j=1} a_{ij}x_{j}\\right)/a_{ii}$ for all $i$\n",
        "\n",
        "What if $A$ is *upper triangular*? We use *backward substitution* and just reverse the order\n",
        "\n",
        ". . .\n",
        "\n",
        "What is the complexity of this algorithm (in $O$ notation)? \n",
        "\n",
        "\n",
        "\n",
        "## Solving linear equations: forward substitution\n",
        "\n",
        "$x_i=\\left(b_i-\\sum^{i-1}_{j=1} a_{ij}x_{j}\\right)/a_{ii}$ for all $i$\n",
        "\n",
        "What is the complexity of this algorithm? \n",
        "\n",
        ". . .\n",
        "\n",
        "There are:\n",
        "\n",
        "- $n$ divisions\n",
        "- $n(n-1)/2$ multiplications\n",
        "- $n(n-1)/2$ additions/subtractions\n",
        "\n",
        "Order of $n^2/2$ operations $\\rightarrow O(n^2)$\n",
        "\n",
        "\n",
        "\n",
        "## LU factorization\n",
        "\n",
        "*In practice we rarely need to solve triangular systems!* What if $A$ is not triangular?\n",
        "\n",
        ". . .\n",
        "\n",
        "1. We decompose $A$ into two matrices: one **U**pper triangular and one **L**ower triangular $\\rightarrow A = LU$\n",
        "  - We use Gaussian elimination for that\n",
        "\n",
        ". . .\n",
        "\n",
        "2. Then, we solve the problem using a combination of forward and backward substitutions\n",
        "  - The system becomes $Ax = (LU)x = L\\underbrace{(Ux)}_{y} = b$\n",
        "  - We solve $Ly = b$ using forward substitution\n",
        "  - Then $Ux = y$ using backward substitution\n",
        "\n",
        "This works for any non-singular matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Gaussian elimination\n",
        "\n",
        "This uses the fact that we can do the following operations to a linear system **without changing its solution**\n",
        "\n",
        "1. multiply one row by a scalar and add to another row\n",
        "2. swap rows\n",
        "\n",
        ". . .\n",
        "\n",
        "We'll use that to turn a matrix $(IA)$ into $(LU)$\n",
        "\n",
        "\n",
        "\n",
        "## LU factorization example\n",
        "\n",
        "Let's see an example with system $Ax = b$\n",
        "\n",
        "$$ A = \n",
        "\\begin{bmatrix}\n",
        "-3 & 2 & 3 \\\\\n",
        "-3 & 2 & 1 \\\\\n",
        "3  & 0 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        ", x = \n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "x_3 \\\\\n",
        "\\end{bmatrix}\n",
        ",\n",
        "b = \n",
        "\\begin{bmatrix}\n",
        "10 \\\\\n",
        "8 \\\\\n",
        "-3 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## LU factorization\n",
        "\n",
        "\n",
        "We start with $I = L, A = U$ and we to make $U$ upper triangular with Gaussian elimination\n",
        "\n",
        "$$ A = \n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "0 & 0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix}\n",
        "-3 & 2 & 3 \\\\\n",
        "-3 & 2 & 1 \\\\\n",
        "3  & 0 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "We do $row2 = row2 - (1)\\times row1$ and $row3 = row3 - (-1)\\times row1$, keeping track of these operations in the $L$ matrix\n",
        "\n",
        "$$ A = \n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "1 & 1 & 0 \\\\\n",
        "-1 & 0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix}\n",
        "-3 & 2 & 3 \\\\\n",
        " 0 & 0 & -2 \\\\\n",
        " 0 & 2 & 3 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## LU factorization example\n",
        "\n",
        "Seems like we are stuck in $U$. But we can swap rows 2 and 3 to make it upper triangular. \n",
        "\n",
        "- *Correspondingly, we need to swap columns 2 and 3 in $L$*\n",
        "\n",
        "\n",
        "$$ A =\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "1 & 0 & 1 \\\\\n",
        "-1 & 1 & 0 \\\\\n",
        "\\end{bmatrix}\\times\n",
        "\\begin{bmatrix} \n",
        "-3 & 2 & 3 \\\\\n",
        " 0 & 2 & 3 \\\\\n",
        " 0 & 0 & -2 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Now we are ready to solve the first part of the problem: $Ly = b$\n",
        "\n",
        "But wait, $L$ is not lower triangular!\n",
        "\n",
        ". . .\n",
        "\n",
        "Not yet. But all we need is for it to be *row-permuted* lower triangular because we can easily swap rows and solve for $y$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## LU factorization example\n",
        "\n",
        "Solving $Ly = b$ we have\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "1 & 0 & 1 \\\\\n",
        "-1 & 1 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix}\n",
        "y_1 \\\\\n",
        "y_2 \\\\\n",
        "y_3 \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "10 \\\\\n",
        "8 \\\\\n",
        "-3 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "is equivalent to\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "-1 & 1 & 0 \\\\\n",
        "1 & 0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix}\n",
        "y_1 \\\\\n",
        "y_2 \\\\\n",
        "y_3 \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "10 \\\\\n",
        "-3 \\\\\n",
        "8 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "which is easy to solve\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## LU factorization example\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "-1 & 1 & 0 \\\\\n",
        "1 & 0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix}\n",
        "y_1 \\\\\n",
        "y_2 \\\\\n",
        "y_3 \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "10 \\\\\n",
        "-3 \\\\\n",
        "8 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        ". . .\n",
        "\n",
        "We solve by forward substitution as\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "y_1 = &  b_1/l_{11} = 10 \\\\\n",
        "y_2 = & (b_2 - l_{21}y_1)/l_{22} = [-3 - (-1)(10)]/1 = 7 \\\\\n",
        "y_3 = & (b_3 - l_{31}y_1 - l_{32}y_2)/l_{33} = [8 - (1)(10) - (0)(7)]/1 = -2\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## LU factorization example\n",
        "\n",
        "Now that we have $y$, we solve $Ux = y$\n",
        "\n",
        "$$ \n",
        "\\begin{bmatrix}\n",
        "-3 & 2 & 3 \\\\\n",
        "0 & 2 & 3 \\\\\n",
        " 0 & 0 & -2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\times\n",
        "\\begin{bmatrix}\n",
        "y_1 \\\\\n",
        "y_2 \\\\\n",
        "y_3 \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "10 \\\\\n",
        "7 \\\\\n",
        "-2 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        ". . .\n",
        "\n",
        "We solve by backward substitution as\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "x_3 = &  y_3/u_{33} = -2/(-2) = 1\\\\\n",
        "x_2 = & (y_2 - u_{23}y_1)/u_{22} = [7 - (3)(1)]/2 = 2 \\\\\n",
        "x_1 = & (y_1 - u_{13}y_1 - u_{12}y_2)/u_{11} = [10 - (3)(1) - (2)(2)]/(-3) = -1\\\\\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "And done!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Why bother with this scheme?\n",
        "\n",
        "Why not just use another method like Cramer's rule?\n",
        "\n",
        ". . .\n",
        "\n",
        "**Speed!**\n",
        "\n",
        ". . .\n",
        "\n",
        "- LU is less than $O(n^3)$\n",
        "- Cramer's rule is $O(n!\\times n)$\n",
        "\n",
        ". . .\n",
        "\n",
        "For a 10x10 system this can really matter:\n",
        "\n",
        "- LU factorization: 430 long operations (`*` and `/`)\n",
        "- Matrix inversion and multiplication: 1,100 long operations\n",
        "- Cramer: 40 million long operations!\n",
        "\n",
        "\n",
        "\n",
        "## Example: LU vs Cramer\n",
        "\n",
        "Julia description of the division operator `\\`:\n",
        "> If A is upper or lower triangular (or diagonal), no factorization of A is required and the system is solved with either forward or backward substitution. For non-triangular square matrices, an LU factorization is used.\n",
        "\n",
        "So we can do LU factorization to solve systems by just doing **`x = A\\b`**. But we could write it ourselves as well\n",
        "\n",
        "\n",
        "\n",
        "## Example: LU vs Cramer\n",
        "\n",
        "Cramer's Rule can be written as a simple loop:"
      ],
      "id": "57ca98cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function solve_cramer(A, b)\n",
        "\n",
        "    dets = Vector(undef, length(b))\n",
        "\n",
        "    for index in eachindex(b)\n",
        "        B = copy(A)\n",
        "        B[:, index] = b\n",
        "        dets[index] = det(B)\n",
        "    end\n",
        "\n",
        "    return dets ./ det(A)\n",
        "\n",
        "end"
      ],
      "id": "b1a6efc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = 1000\n",
        "A = rand(n, n)\n",
        "b = rand(n)"
      ],
      "id": "789467dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: LU vs Cramer\n",
        "\n",
        "Let's see the full results of the competition for a 1,000 x 1,000 matrix:"
      ],
      "id": "d8ea7b96"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using BenchmarkTools\n",
        "cramer_time = @elapsed solve_cramer(A, b);\n",
        "cramer_allocation = @allocated solve_cramer(A, b);\n",
        "lu_time = @elapsed A\\b;\n",
        "lu_allocation = @allocated A\\b;\n",
        "\n",
        "println(\n",
        "\"Cramer's rule solved in $cramer_time seconds and used $cramer_allocation kilobytes of memory.\n",
        "LU solved in $(lu_time) seconds and used $(lu_allocation) kilobytes of memory.\n",
        "LU is $(round(cramer_time/lu_time, digits = 0)) times faster \n",
        " and uses $(round(lu_allocation/cramer_allocation*100, digits = 2))%  of the memory.\")"
      ],
      "id": "184a3a55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: LU vs matrix inversion\n",
        "\n",
        "Let's see the full results of the competition for a 1,000 x 1,000 matrix:"
      ],
      "id": "41f9a579"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using BenchmarkTools\n",
        "invers_time = @elapsed ((A^-1)*b);\n",
        "invers_allocation = @allocated ((A^-1)*b);\n",
        "\n",
        "println(\n",
        "\"Matrix inversion solved in $invers_time seconds and used $invers_allocation kilobytes of memory.\n",
        "LU solved in $(lu_time) seconds and used $(lu_allocation) kilobytes of memory.\n",
        "LU is $(round(invers_time/lu_time, digits = 2)) times faster\n",
        " and uses $(round(lu_allocation/invers_allocation*100, digits = 2))%  of the memory.\")"
      ],
      "id": "12665a95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other factorizations\n",
        "\n",
        "LU is not the only direct method used to speed up linear equation solvers\n",
        "\n",
        "- QR factorization decomposes $A = QR$, where $Q$ is an orthogonal matrix and $R$ is upper triangular\n",
        "- Cholesky factorization can be used if $A$ is positive definite\n",
        "  - This is particularly useful in optimization, where we often get matrices like that\n",
        "- There are also methods optimized for sparse matrices\n",
        "\n",
        "Chapter 3 in Judd has a summary and references of other methods if you need them for your research in the future\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Rounding error blow-up\n",
        "\n",
        "In practice, Gaussian elimination can lead to *very inaccurate* solutions. For example:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "-M^{-1} & 1 \\\\\n",
        "1 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1 \\\\\n",
        "2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "where $M$ is a large positive number\n",
        "\n",
        ". . .\n",
        "\n",
        "Suppose we use LU factorization to solve it\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "-M^{-1} & 1 \\\\\n",
        "1 & 1\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1 & 0\\\\\n",
        "0 & 1\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "-M^{-1} & 1 \\\\\n",
        "1 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## Numerical error blow-up\n",
        "\n",
        "Subtract $-M$ times the first row from the second to get the LU factorization\n",
        "\\begin{align*}\n",
        "\t\t\\begin{bmatrix}\n",
        "\t  1&  0 \\\\\n",
        "\t\t0 & 1\n",
        "\t\\end{bmatrix}\n",
        "\t\\begin{bmatrix}\n",
        "\t    -M^{-1} & 1 \\\\\n",
        "\t\t1 & 1\n",
        "\t\\end{bmatrix}\n",
        "\t=\n",
        "\t\\begin{bmatrix}\n",
        "\t    1 & 0\\\\\n",
        "\t    -M & 1\n",
        "\t\\end{bmatrix}\n",
        "\t\\begin{bmatrix}\n",
        "\t    -M^{-1} & 1\\\\\n",
        "\t    0 & M+1\n",
        "\t\\end{bmatrix}\n",
        "\\end{align*}\n",
        "\n",
        ". . .\n",
        "\n",
        "We can get closed-form solutions by applying forward substitution:\n",
        "\\begin{align*}\n",
        "\t\\begin{bmatrix}\n",
        "\t    x_1\\\\\n",
        "\t    x_2\n",
        "\t\\end{bmatrix}\n",
        "\t=\n",
        "\t\\begin{bmatrix}\n",
        "\t    M/(M+1)\\\\\n",
        "\t    (M+2)/(M+1)\n",
        "\t\\end{bmatrix}\n",
        "\\end{align*}\n",
        "\n",
        "\n",
        "\n",
        "## Numerical error blow-up\n",
        "\n",
        "When $M$ is large, both variables are approximately 1 \n",
        "\n",
        "- But remember adding small numbers to big numbers causes problems numerically\n",
        "\n",
        ". . .\n",
        "\n",
        "If $M=10000000000000000000$, the computer will return $x_2$ is equal to precisely $1$\n",
        "\n",
        "- This isn't terribly wrong\n",
        "\n",
        ". . .\n",
        "\n",
        "When we then perform the second step of backwards substitution, we solve for $x_1=-M(1-x_2) = 0$, this is **VERY** wrong\n",
        "\n",
        ". . .\n",
        "\n",
        "**Large errors like this often occur because diagonal elements are very small**\n",
        "\n",
        "\n",
        "\n",
        "## A numerical error blow-up solution\n",
        "\n",
        "**Large errors like this often occur because diagonal elements are very small**\n",
        "\n",
        "In some cases, this can be solved by **pivoting**: we swap two rows so that small numbers are off-diagonal\n",
        "\n",
        "- Swapping rows does not change the solution and may prevent operations causing rounding errors\n",
        "\n",
        ". . .\n",
        "\n",
        "Most numerical linear algebra packages will do this for you (including the one embedded in Julia)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Numerical error blow-up: Julia example\n"
      ],
      "id": "d0b96a24"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function solve_lu(M)\n",
        "    b = [1, 2]\n",
        "    U = [-M^-1 1; 0 M+1]\n",
        "    L = [1. 0; -M 1.]\n",
        "    y = L\\b\n",
        "    # Round element-wise to 3 digits\n",
        "    x = round.(U\\y, digits = 5)\n",
        "end;\n",
        "\n",
        "true_solution(M) = round.([M/(M+1), (M+2)/(M+1)], digits = 5);\n",
        "println(\"True solution for M=10   is approx. $(true_solution(10)), computed solution is $(solve_lu(10))\");\n",
        "println(\"True solution for M=1e10 is approx. $(true_solution(1e10)), computed solution is $(solve_lu(1e10))\");\n",
        "println(\"True solution for M=1e15 is approx. $(true_solution(1e15)), computed solution is $(solve_lu(1e15))\");\n",
        "println(\"True solution for M=1e20 is approx. $(true_solution(1e20)), computed solution is $(solve_lu(1e20))\");"
      ],
      "id": "fdd98f34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Numerical error blow-up: Julia example\n"
      ],
      "id": "a2167696"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "println(\"True solution for M=10 is approximately $(true_solution(10)), computed solution is $(solve_lu(10))\")\n",
        "println(\"True solution for M=1e10 is approximately $(true_solution(1e10)), computed solution is $(solve_lu(1e10))\")\n",
        "println(\"True solution for M=1e15 is approximately $(true_solution(1e15)), computed solution is $(solve_lu(1e15))\")\n",
        "println(\"True solution for M=1e20 is approximately $(true_solution(1e20)), computed solution is $(solve_lu(1e20))\")"
      ],
      "id": "27131da4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "M = 1e20;\n",
        "A = [-M^-1 1; 1 1];\n",
        "b = [1., 2.];\n",
        "julia_solution = A\\b;\n",
        "println(\"Julia's division operator is actually pretty smart though,\n",
        "        true solution for M=1e20 is $(julia_solution)\")"
      ],
      "id": "720d7a1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ill-conditioning\n",
        "\n",
        "A matrix $A$ is said to be ill-conditioned if a small perturbation in $b$ yields a large change in $x$\n",
        "\n",
        ". . .\n",
        "\n",
        "One way to measure ill-conditioning in a matrix is the elasticity of the solution with respect to $b$,\n",
        "\n",
        "$$\n",
        "\\sup_{||\\delta b || > 0} \\frac{||\\delta x|| / ||x||}{||\\delta b|| / ||b||}\n",
        "$$\n",
        "which yields the percent change in $x$ given a percentage point change in the magnitude of $b$\n",
        "\n",
        "\n",
        "\n",
        "## Ill-conditioning\n",
        "\n",
        "If this elasticity is large, then then small errors in the representation of $b$ can lead to large errors in the computed solution $x$\n",
        "\n",
        ". . .\n",
        "\n",
        "Calculating this elasticity is computationally expensive. We approximate it by calculating the **condition number**\n",
        "$$\n",
        "\\kappa = ||A|| \\cdot ||A^{-1}||\n",
        "$$\n",
        "\n",
        ". . .\n",
        "\n",
        "$\\kappa$ gives the least upper bound of the elasticity and is always larger than one\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Ill-conditioning\n",
        "\n",
        "Rule of thumb: *for each power of 10, a significant digit is lost in the computation of* $x$\n"
      ],
      "id": "5952e7e5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using LinearAlgebra;\n",
        "cond([1. 1.; 1. 1.0001])\n",
        "cond([1. 1.; 1. 1.00000001])\n",
        "cond([1. 1.; 1. 1.000000000001])"
      ],
      "id": "1aa04092",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- *(In Python, package `numpy` implements condition number calculation with method [`linalg.cond`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.cond.html))*\n",
        "\n",
        "\n",
        "## Iterative methods\n",
        "\n",
        "Direct methods like LU factorization work well for relatively small matrices. As $n$ gets bigger, the time and memory needed becomes prohibitive\n",
        "\n",
        ". . .\n",
        "\n",
        "When that happens, we use **iterative methods** instead\n",
        "\n",
        "- They require less memory\n",
        "- Adequate iterative methods can give a good answer in reasonable time\n",
        "\n",
        ". . .\n",
        "\n",
        "Let's start with the simplest and most intuitive iterative method\n",
        "\n",
        "\n",
        "\n",
        "## Fixed-point iteration\n",
        "\n",
        "Main idea: *we reformulate our problem as a fixed-point problem and iterate it the mapping*\n",
        "\n",
        ". . .\n",
        "\n",
        "Instead of $Ax = b$, we define $G(x) \\equiv Ax - b + x$\n",
        "\n",
        ". . .\n",
        "\n",
        "We start with an initial guess in step $k=0$ and compute the next values using\n",
        "\n",
        "$$x^{(k+1)} = G(x^{(k)}) = (A + I)x^{(k)} - b$$\n",
        "\n",
        ". . .\n",
        "\n",
        "When we find a fixed point (i.e, $x = G(x)$), we know that $x$ solves our initial problem $Ax = b$ \n",
        "\n",
        ". . .\n",
        "\n",
        "We don't use this method though because it is very particular: it only converges if all eigenvalues of $(A + I)$ have modulus less than one\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Operator Splitting methods\n",
        "\n",
        "\n",
        "In a more useful method, we can rewrite $Ax=b$ as $Qx = b + (Q - A)x$ for some square matrix $Q$\n",
        "\n",
        ". . .\n",
        "\n",
        "Rearranging, we get $x = Q^{-1}b + (I - Q^{-1}A)x$, which suggests the iterating rule\n",
        "\n",
        "$$x^{(k+1)} = Q^{-1}b + (I - Q^{-1}A)x^{(k)} $$\n",
        ". . .\n",
        "\n",
        "It is easy to check that if $x^{(k+1)}=x^{(k)}$, then $x^{(k)}$ is a solution to $Ax=b$\n",
        "\n",
        ". . .\n",
        "\n",
        "- This approach can be used in nonlinear systems, too!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Operator Splitting methods\n",
        "\n",
        "$Q$ is called the **splitting matrix**. That's because it effectively splits $A$ into $A = Q - P$\n",
        "\n",
        "In practice, we choose $Q$ so that\n",
        "\n",
        "1. $Q^{-1}b$ and $Q^{-1}a$ are easy to compute (like when $Q$ is diagonal or triangular)\n",
        "2. $||I - Q^{-1}A ||< 1$ so we know the iteration converges\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Gauss-Jacobi method\n",
        "\n",
        "When $Q$ is chosen to be a diagonal matrix with the same diagonal elements in $A$, we have the **Gauss-Jacobi method**\n",
        "\n",
        ". . .\n",
        "\n",
        "The intuition is simple:  \n",
        "\n",
        "- For every equation in this system, we can always write $x_i = \\frac{1}{a_{ii}}[b_i - \\sum_{j \\neq i}a_{ij}x_j]$\n",
        "- We use this equation to formulate the iteration rule\n",
        "\n",
        "$$x_i^{(k+1)} = \\frac{1}{a_{ii}}[b_i - \\sum_{j \\neq i}a_{ij}x_j^{(k)}]$$ \n",
        "\n",
        "\n",
        "\n",
        "## Gauss-Jacobi method\n",
        "\n",
        "Iteration rule\n",
        "\n",
        "$$x_i^{(k+1)} = \\frac{1}{a_{ii}}[b_i - \\sum_{j \\neq i}a_{ij}x_j^{(k)}]$$ \n",
        "\n",
        "Then, we assume initial values $x_i^{(0)} \\; \\forall i$ and iterate all $x_i$ simultaneously *until convergence*\n",
        "\n",
        ". . .\n",
        "\n",
        "$\\Rightarrow$ we turned a \" $n$ equations with $n$ unknowns\" into repeatedly solving $n$ equations with *1* unknown\n",
        "\n",
        "\n",
        "\n",
        "## Convergence\n",
        "\n",
        "**What do we mean by *until convergence*?**\n",
        "\n",
        ". . .\n",
        "\n",
        "This is a parameter you have to choose\n",
        "\n",
        "- Usually, we will set a `tolerance` value\n",
        "- Then, in each iteration, we take some metric of the difference $\\delta_x$ between $x^{k+1}$ and $x^{k}$\n",
        "- If $d_x <$ `tolerance`, we stop iterating and declare $x^{k+1}$ our solution \n",
        "\n",
        "The actual choice of `tolerance` will depend on the scale of your variables and the desired precision\n",
        "\n",
        "\n",
        "\n",
        "## Convergence\n",
        "\n",
        "\n",
        "It is a good practice to set a `max_iterations` parameter to stop your code once a maximum number of iterations have run\n",
        "\n",
        "- This avoids your code getting into an **infinite loop** if your method turn out not to converge\n",
        "\n",
        "You can do that by incrementing a variable that counts the number of iterations and testing the condition `iteration <= max_iterations` before proceeding\n",
        "\n",
        "- If your hit the maximum number of iteration, it's a sign your solution did not converge\n",
        "\n",
        "\n",
        "\n",
        "## Convergence\n",
        "\n",
        "An example of how to test both the convergence and maximum iteration conditions is "
      ],
      "id": "0a95c052"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dx = Inf # Start with a very large number\n",
        "tol = 1e-6 # One example\n",
        "iteration = 0 # Initialize value\n",
        "max_iterations = 1000 # Set max of 1000 iterations\n",
        "while (dx >= tol && iteration <= max_iterations)\n",
        "  iteration = iteration + 1\n",
        "  # Here you iterate your solutions and recalculate dx\n",
        "end"
      ],
      "id": "403255ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gauss-Seidel method\n",
        "\n",
        "The Gauss-Seidel method chooses $Q$ as an *upper triangular matrix* with the same elements in $A$ \n",
        "\n",
        ". . .\n",
        "\n",
        "Here is the intuition behind it\n",
        "\n",
        "In Gauss-Jacobi, we only use a new guess $x^{(k+1)}$ after we've computed all $x_i^{(k+1)}$\n",
        "\n",
        "- For example, we use $x_1^{k}$ to calculate $x_2^{(k+1)}$ even though we already have $x_1^{(k+1)}$\n",
        "\n",
        "We can make faster use of information if we use our newly calculated guesses right away. That is what the *Gauss-Seidel method* does\n",
        "\n",
        "\n",
        "\n",
        "## Gauss-Seidel method\n",
        "\n",
        "So, when we compute the new guess for $x_2$, we have $x_2^{(k+1)} = (b_2 - a_{21}x_1^{(k+1)} - a_{23}x_1^{(k)} - \\dots)/a_{22}$ \n",
        "\n",
        "This give the iteration rule\n",
        "\n",
        "$$x_i^{(k+1)} = \\frac{1}{a_{ii}}[b_i - \\sum_{j = 1}^{i-1}a_{ij}x_j^{(k+1)} - \\sum_{j = i+1}^{n}a_{ij}x_j^{(k)} ]$$ \n",
        "\n",
        ". . .\n",
        "\n",
        "Unlike Gauss-Jacobi, **in Gauss-Seidel the order equations matters**\n",
        "\n",
        "- This also makes Gauss-Seidel more flexible, because we can try different orders to get it to converge\n",
        "\n",
        "\n",
        "\n",
        "## A visual example\n",
        "\n",
        "*Tâttonement* is an old concept (Walras, 1954) to describe how markets reach equilibrium by trial-and-error\n",
        "\n",
        ". . .\n",
        "\n",
        "1. An initial price is fixed\n",
        "2. Demanded and supplied quantities are announced based on that price\n",
        "3. If quantities don't match, a (Walrasian) auctioneer announces a new price and the process repeats until we reach an equilibrium\n",
        "  - If there is oversupply, lower the price\n",
        "  - If there is overdemand, raise the price\n",
        "\n",
        ". . .\n",
        "\n",
        "We can use this concept to illustrate iterative solution methods with linear demand/supply equations\n",
        "\n",
        "\n",
        "\n",
        "## A visual example\n",
        "\n",
        "Let's consider the simple linear demand/supply problem\n",
        "\n",
        "- Inverse demand: $p = 10 - q$\n",
        "- Supply: $q = p/2 + 1$\n",
        "\n",
        ". . .\n",
        "\n",
        "To solve it, we form the system\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 1 \\\\\n",
        "1 & -2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "p \\\\\n",
        "q \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "10 \\\\\n",
        "-2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        ". . .\n",
        "\n",
        "From Gauss-Jacobi iteration rule\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "p^{(k+1)} = (10 - q^{(k)})/1 & = 10 - q^{(k)}\\\\\n",
        "q^{(k+1)} = (-2 - p^{(k)})/(-2) & = 1 + p^{(k)}/2\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Jacobi\n",
        "\n",
        "But let's see how that rule comes from matrix form\n",
        "\n",
        "$$\n",
        "A=\n",
        "\\begin{bmatrix}\n",
        "1 & 1 \\\\\n",
        "1 & -2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\Rightarrow\n",
        "Q =\n",
        "\\begin{bmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & -2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\Rightarrow\n",
        "Q^{-1} =\n",
        "\\begin{bmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & -1/2 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "So $x^{(k+1)} = Q^{-1}b + (I - Q^{-1}A)x^{(k)}$ gives\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "p^{(k+1)} \\\\\n",
        "q^{(k+1)} \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & -1/2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "10 \\\\\n",
        "-2\n",
        "\\end{bmatrix}\n",
        "+\\left(\n",
        "\\begin{bmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "-\n",
        "\\begin{bmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & -1/2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "1 & 1 \\\\\n",
        "1 & -2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\right)\n",
        "\\begin{bmatrix}\n",
        "p^{(k)} \\\\\n",
        "q^{(k)} \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        ". . .\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "p^{(k+1)} \\\\\n",
        "q^{(k+1)} \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "10 \\\\\n",
        "1\n",
        "\\end{bmatrix}\n",
        "+\n",
        "\\begin{bmatrix}\n",
        "0 & -1 \\\\\n",
        "1/2 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "p^{(k)} \\\\\n",
        "q^{(k)} \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Jacobi\n",
        "\n",
        "::: {.columns}\n",
        "::: {.column}\n",
        "Let's start from initial guess $q_0=1$ and $p_0=4$ and see how Gauss-Jacobi proceeds\n",
        "\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k)}$\n",
        ":::\n",
        "::: {.column}\n",
        "![](figures/tattonement-Base.png)\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Jacobi\n",
        "\n",
        "::: {.columns}\n",
        "::: {.column}\n",
        "\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k)}$\n",
        "\n",
        "So\n",
        "\n",
        "$q_1 = 1 + (4)/2 = 3$\n",
        ":::\n",
        "::: {.column}\n",
        "![](figures/tattonement-GJ-0p.png)\n",
        ":::\n",
        ":::\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Jacobi\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GJ-0p.png\" height=550>\n",
        "</div>\n",
        "\n",
        ".blue[\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k)}$\n",
        "]\n",
        "\n",
        "So\n",
        "\n",
        "$q_1 = 1 + (4)/2 = 3$\n",
        "\n",
        "$p_1 = 10 - 1 = 9$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Jacobi\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GJ-1.png\" height=550>\n",
        "</div>\n",
        "\n",
        ".blue[\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k)}$\n",
        "]\n",
        "\n",
        "So\n",
        "\n",
        "$q_1 = 1 + (4)/2 = 3$\n",
        "\n",
        "$p_1 = 10 - 1 = 9$\n",
        "\n",
        "And we move to $(3,9)$\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Jacobi\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GJ-2.png\" height=550>\n",
        "</div>\n",
        "\n",
        ".blue[\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k)}$\n",
        "]\n",
        "\n",
        "Next, we get\n",
        ". . .\n",
        "\n",
        "$q_2 = 1 + (9)/2 = 5.5$\n",
        "\n",
        "$p_2 = 10 - 3 = 7$\n",
        "\n",
        "And we move to $(5.5,7)$\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Jacobi\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GJ-3.png\" height=550>\n",
        "</div>\n",
        "\n",
        ".blue[\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k)}$\n",
        "]\n",
        "\n",
        "Then, we get\n",
        ". . .\n",
        "\n",
        "$q_3 = 1 + (7)/2 = 4.5$\n",
        "\n",
        "$p_3 = 10 - 5.5 = 4.5$\n",
        "\n",
        "And we move to $(4.5,4.5)$\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Jacobi\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GJ-4.png\" height=550>\n",
        "</div>\n",
        "\n",
        ".blue[\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k)}$\n",
        "]\n",
        "\n",
        "And we continue to process until the difference between $(q^{(k+1)},p^{(k+1)})$ and $(q^{(k)},p^{(k)})$ is smaller than our `tolerance` parameter (i.e., it converges)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Seidel\n",
        "\n",
        "The Gauss-Seidel iteration rules looks similar, but there is an important difference\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "q^{(k+1)} & = 1 + p^{(k)}/2 \\\\\n",
        "p^{(k+1)} & = 10 - \\mathbf{q^{(k+1)}}\n",
        "\\end{align*}\n",
        "$$\n",
        ". . .\n",
        "\n",
        "$p^{(k+1)}$ is a function of $q^{(k+1)}$, not $q^{(k)}$\n",
        "\n",
        ". . .\n",
        "\n",
        "- Note that we could plug the 1st equation into the 2nd: $p^{(k+1)}  = 9 - p^{(k)}/2$ \n",
        "\n",
        ". . .\n",
        "\n",
        "- In this case, the example starts with an iteration over $q$. Starting with $p$ is also possible *but gives a different sequence of steps*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Seidel\n",
        "\n",
        "Let's see how that rule comes from matrix form\n",
        "\n",
        "$$\n",
        "A=\n",
        "\\begin{bmatrix}\n",
        "1 & 1 \\\\\n",
        "1 & -2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\Rightarrow\n",
        "Q =\n",
        "\\begin{bmatrix}\n",
        "1 & 1 \\\\\n",
        "0 & -2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\Rightarrow\n",
        "Q^{-1} =\n",
        "\\begin{bmatrix}\n",
        "1 & 1/2 \\\\\n",
        "0 & -1/2 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "So $x^{(k+1)} = Q^{-1}b + (I - Q^{-1}A)x^{(k)}$ gives\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "p^{(k+1)} \\\\\n",
        "q^{(k+1)} \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1 & 1/2 \\\\\n",
        "0 & -1/2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "10 \\\\\n",
        "-2\n",
        "\\end{bmatrix}\n",
        "+\\left(\n",
        "\\begin{bmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "-\n",
        "\\begin{bmatrix}\n",
        "1 & 1/2 \\\\\n",
        "0 & -1/2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "1 & 1 \\\\\n",
        "1 & -2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\right)\n",
        "\\begin{bmatrix}\n",
        "p^{(k)} \\\\\n",
        "q^{(k)} \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "p^{(k+1)} \\\\\n",
        "q^{(k+1)} \\\\\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "9 \\\\\n",
        "1\n",
        "\\end{bmatrix}\n",
        "+\n",
        "\\begin{bmatrix}\n",
        "-1/2 & 0 \\\\\n",
        "1/2 & 0 \\\\\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "p^{(k)} \\\\\n",
        "q^{(k)} \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Seidel\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-Base.png\" height=550>\n",
        "</div>\n",
        "\n",
        "Once again, we start from initial guess $q_0=1$ and $p_0=4$\n",
        "\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k+1)}$\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Seidel\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GS-1.png\" height=550>\n",
        "</div>\n",
        "\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k+1)}$\n",
        "\n",
        "So\n",
        "\n",
        "$q_1 = 1 + (4)/2 = 3$\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Seidel\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GS-2.png\" height=550>\n",
        "</div>\n",
        "\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k+1)}$\n",
        "\n",
        "So\n",
        "\n",
        "$q_1 = 1 + (4)/2 = 3$\n",
        "\n",
        "$p_1 = 10 - (3) = 7$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Seidel\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GS-3.png\" height=550>\n",
        "</div>\n",
        "\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k+1)}$\n",
        "\n",
        "So\n",
        "\n",
        "$q_1 = 1 + (4)/2 = 3$\n",
        "\n",
        "$p_1 = 10 - (3) = 7$\n",
        "\n",
        "$q_2 = 1 + (7)/2 = 4.5$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Seidel\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GS-4.png\" height=550>\n",
        "</div>\n",
        "\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k+1)}$\n",
        "\n",
        "So\n",
        "\n",
        "$q_1 = 1 + (4)/2 = 3$\n",
        "\n",
        "$p_1 = 10 - (3) = 7$\n",
        "\n",
        "$q_2 = 1 + (7)/2 = 4.5$\n",
        "\n",
        "$p_2 = 10 - 4.5 = 5.5$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## A visual example: Gauss-Seidel\n",
        "\n",
        "<div style=\"float:right\">\n",
        " <image src=\"figures/tattonement-GS-5.png\" height=550>\n",
        "</div>\n",
        "\n",
        "The iteration rules are\n",
        "\n",
        "$q^{(k+1)} = 1 + p^{(k)}/2$\n",
        "\n",
        "$p^{(k+1)} = 10 - q^{(k+1)}$\n",
        "\n",
        "And we continue to process until the difference between $(q^{(k+1)},p^{(k+1)})$ and $(q^{(k)},p^{(k)})$ is smaller than our `tolerance` parameter (i.e., it converges)\n",
        "\n",
        "\n",
        "\n",
        "## Acceleration and Stabilization methods\n",
        "\n",
        "- When our iterations converge too slowly or diverge, we can try **acceleration** or **stabilization** methods\n",
        "  - These concepts also work for nonlinear equations and optimization\n",
        "\n",
        ". . .\n",
        "\n",
        "These methods are conceptually simple: we will multiply our step $x^{(k)}\\rightarrow x^{(k+1)}$ by a scalar $\\omega$\n",
        "\n",
        "\n",
        "\n",
        "## Acceleration and Stabilization methods\n",
        "\n",
        "- When $\\omega > 1$, it's called **extrapolation**: we're taking a *bigger step*\n",
        "  - Idea: if the method converges, then the direction $x^{(k)}\\rightarrow x^{(k+1)}$ is a good move, so it could be even better to go beyond $x^{(k+1)}$ and converge faster\n",
        "\n",
        ". . .\n",
        "\n",
        "- When $\\omega < 1$, it's called **dampening**: we're taking a *smaller step*\n",
        "  - Idea: maybe the direction $x^{(k)}\\rightarrow x^{(k+1)}$ is a good one, but we are overshooting, so if we stop short of $x^{(k+1)}$, we may get it to converge\n",
        "\n",
        "<div align=\"center\">\n",
        " <image src=\"figures/dampening_extrap.png\" height=250>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "## Acceleration and Stabilization methods\n",
        "\n",
        "Returning to our Gauss-Seidel example, **accelerating** the solution with **extrapolation** could look like this \n",
        "\n",
        "<div align=\"center\">\n",
        " <image src=\"figures/tattonement-GS-extrap.png\" height=450>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Acceleration and Stabilization methods\n",
        "\n",
        "And, **stabilizing** the solution with **dampening** could look like this \n",
        "\n",
        "<div align=\"center\">\n",
        " <image src=\"figures/tattonement-GS-dampen.png\" height=450>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Acceleration and Stabilization methods\n",
        "\n",
        "These methods don't always work. It may be a good idea to try if you are having issues with slow convergence or divergence\n",
        "\n",
        "We'll skip the technical details of when these methods work for operator splitting\n",
        "\n",
        "- You can find them in chapter 3 of Judd's textbook \n"
      ],
      "id": "7da0ccef"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.9",
      "language": "julia",
      "display_name": "Julia 1.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}